{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7416fa-7f40-4027-9279-4175563a49a9",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## 1. Load the Data\n",
    "\n",
    "We will start by loading the dataset and examining its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5e0e6cc6-59e3-4a43-a1aa-0d02a3618a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>dt_iso</th>\n",
       "      <th>timezone</th>\n",
       "      <th>city_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>temp</th>\n",
       "      <th>visibility</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_gust</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>rain_3h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>snow_3h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>weather_icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1407628800</td>\n",
       "      <td>2014-08-10 00:00:00 +0000 UTC</td>\n",
       "      <td>7200</td>\n",
       "      <td>Custom location</td>\n",
       "      <td>52.497492</td>\n",
       "      <td>13.349695</td>\n",
       "      <td>14.97</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>14.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>741</td>\n",
       "      <td>Fog</td>\n",
       "      <td>fog</td>\n",
       "      <td>50n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1407632400</td>\n",
       "      <td>2014-08-10 01:00:00 +0000 UTC</td>\n",
       "      <td>7200</td>\n",
       "      <td>Custom location</td>\n",
       "      <td>52.497492</td>\n",
       "      <td>13.349695</td>\n",
       "      <td>14.97</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>14.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>741</td>\n",
       "      <td>Fog</td>\n",
       "      <td>fog</td>\n",
       "      <td>50n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1407636000</td>\n",
       "      <td>2014-08-10 02:00:00 +0000 UTC</td>\n",
       "      <td>7200</td>\n",
       "      <td>Custom location</td>\n",
       "      <td>52.497492</td>\n",
       "      <td>13.349695</td>\n",
       "      <td>13.97</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>13.02</td>\n",
       "      <td>13.88</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>741</td>\n",
       "      <td>Fog</td>\n",
       "      <td>fog</td>\n",
       "      <td>50n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1407639600</td>\n",
       "      <td>2014-08-10 03:00:00 +0000 UTC</td>\n",
       "      <td>7200</td>\n",
       "      <td>Custom location</td>\n",
       "      <td>52.497492</td>\n",
       "      <td>13.349695</td>\n",
       "      <td>13.97</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>13.02</td>\n",
       "      <td>13.88</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>741</td>\n",
       "      <td>Fog</td>\n",
       "      <td>fog</td>\n",
       "      <td>50n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1407643200</td>\n",
       "      <td>2014-08-10 04:00:00 +0000 UTC</td>\n",
       "      <td>7200</td>\n",
       "      <td>Custom location</td>\n",
       "      <td>52.497492</td>\n",
       "      <td>13.349695</td>\n",
       "      <td>14.97</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>14.01</td>\n",
       "      <td>14.98</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>Clear</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>01d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt                         dt_iso  timezone        city_name  \\\n",
       "0  1407628800  2014-08-10 00:00:00 +0000 UTC      7200  Custom location   \n",
       "1  1407632400  2014-08-10 01:00:00 +0000 UTC      7200  Custom location   \n",
       "2  1407636000  2014-08-10 02:00:00 +0000 UTC      7200  Custom location   \n",
       "3  1407639600  2014-08-10 03:00:00 +0000 UTC      7200  Custom location   \n",
       "4  1407643200  2014-08-10 04:00:00 +0000 UTC      7200  Custom location   \n",
       "\n",
       "         lat        lon   temp  visibility  dew_point  feels_like  ...  \\\n",
       "0  52.497492  13.349695  14.97     10000.0      13.00       14.82  ...   \n",
       "1  52.497492  13.349695  14.97     10000.0      13.00       14.82  ...   \n",
       "2  52.497492  13.349695  13.97     10000.0      13.02       13.88  ...   \n",
       "3  52.497492  13.349695  13.97     10000.0      13.02       13.88  ...   \n",
       "4  52.497492  13.349695  14.97     10000.0      14.01       14.98  ...   \n",
       "\n",
       "   wind_gust  rain_1h  rain_3h  snow_1h  snow_3h  clouds_all  weather_id  \\\n",
       "0        NaN      NaN      NaN      NaN      NaN           0         741   \n",
       "1        NaN      NaN      NaN      NaN      NaN           0         741   \n",
       "2        NaN      NaN      NaN      NaN      NaN           0         741   \n",
       "3        NaN      NaN      NaN      NaN      NaN           0         741   \n",
       "4        NaN      NaN      NaN      NaN      NaN           0         800   \n",
       "\n",
       "   weather_main  weather_description  weather_icon  \n",
       "0           Fog                  fog           50n  \n",
       "1           Fog                  fog           50n  \n",
       "2           Fog                  fog           50n  \n",
       "3           Fog                  fog           50n  \n",
       "4         Clear         sky is clear           01d  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('berlin_weather_2014_2023.csv')\n",
    "\n",
    "# Check the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd415d2-a996-487f-b04e-8bd3ee24aa90",
   "metadata": {},
   "source": [
    "#### 1.1 Splitting and Cleaning Data Columns:\n",
    "\n",
    "To enhance the dataset's organization and clarity, we will perform the following steps to split and clean specific columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8220f191-f16c-40ff-abc5-675a01477d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'dt_iso' column into separate columns\n",
    "df[['date', 'time', 'timezone','zone_sign']] = df['dt_iso'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eca723-22e3-407f-b019-8112996a4280",
   "metadata": {},
   "source": [
    "#### 1.2 Removing Redundant Columns:\n",
    "We will remove the following columns as they are no longer needed for analysis\n",
    "city_name, lat, lon, timezone, sea_level, grnd_level, snow_3h\n",
    "\n",
    "they either have the same value or Null value for all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e5bb87fc-133e-4ec1-96e2-71c5a3031467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary and redundant columns\n",
    "columns_to_drop = ['dt_iso','city_name', 'lat', 'lon', 'timezone', 'sea_level', 'grnd_level', 'snow_3h','zone_sign']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40018460-7857-4594-913f-d3d62f86502f",
   "metadata": {},
   "source": [
    "#### 1.3 Handling Missing Values\n",
    "Before using the data to train a machine learning model, it's essential to handle any missing values.\n",
    "\n",
    "Filling the empty rows with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a86707e5-f533-47a8-8b34-e14cab02bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211bbf70-8b52-4717-add3-51efdceb8ccb",
   "metadata": {},
   "source": [
    "#### 1.4 Scaling Features\n",
    "Many machine learning models perform better when numerical features have the same scale.\n",
    "\n",
    "##### The main reasons for scaling are:\n",
    "\n",
    "Algorithms Performance: Many machine learning algorithms, especially those that use gradient descent as an optimization technique, require data to be scaled. If features have vastly different scales, the algorithm might prioritize the feature with a larger scale over the smaller one, even if they are equally important. This can lead to sub-optimal performance.\n",
    "\n",
    "- Convergence: Algorithms might converge (i.e., find a solution) faster if data is scaled.\n",
    "\n",
    "- Interpretability: It can help in comparing the importance of different features in some models.\n",
    "\n",
    "For our purposes, we'll use Standard Scaling.\n",
    "\n",
    "This scales the data so that it has a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bca3b851-2274-4c2f-b762-2260a992b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize a scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler and transform the temperature and humidity columns\n",
    "df['scaled_temp'] = scaler.fit_transform(df[['temp']])\n",
    "df['scaled_humidity'] = scaler.fit_transform(df[['humidity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74767a9-9608-4742-9b63-934c11314768",
   "metadata": {},
   "source": [
    "#### 1.5 Feature Engineering \n",
    "Given time series data, we can generate some derived features to help the model capture patterns:\n",
    "\n",
    "Feature engineering is the process of using domain knowledge to extract additional features from raw data. These features can improve the performance of machine learning models. The process might include:\n",
    "\n",
    "Feature Transformation: Creating new features from the existing ones. This can be done using various mathematical operations like logarithms, polynomial features, etc.\n",
    "\n",
    "Encoding Categorical Data: Many machine learning models require inputs to be numeric. If your data includes categorical variables (like \"red\", \"blue\", \"green\"), you need to encode them into numbers. Common methods include one-hot encoding and label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cfc3b116-ca2d-49ce-ba24-73b9348bdc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a rolling average of temperature and humidity for the past 7 days\n",
    "df['rolling_avg_temp'] = df['scaled_temp'].rolling(window=7).mean()\n",
    "df['rolling_avg_humidity'] = df['scaled_humidity'].rolling(window=7).mean()\n",
    "\n",
    "# Create lag features for temperature and humidity (previous day's values)\n",
    "df['lag_temp'] = df['scaled_temp'].shift(1)\n",
    "df['lag_humidity'] = df['scaled_humidity'].shift(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674ed86a-f4fd-43a4-a724-34240da2cb94",
   "metadata": {},
   "source": [
    "##### Handling NaN values in Rolling Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "05644ad5-42f7-4f8e-a37e-648a7400e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rolling_avg_temp'].fillna(df['rolling_avg_temp'].mean(), inplace=True)\n",
    "df['rolling_avg_humidity'].fillna(df['rolling_avg_humidity'].mean(), inplace=True)\n",
    "df['lag_temp'].fillna(df['lag_temp'].mean(), inplace=True)\n",
    "df['lag_humidity'].fillna(df['lag_humidity'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe412623-3c59-4121-a002-149eea592bcb",
   "metadata": {},
   "source": [
    "##### dropping unneccesary string columns\n",
    "dropping:\n",
    "- weather_icon\n",
    "- weather_main\n",
    "- weather_description\n",
    "\n",
    "as weather description is a further explanation of weather_main.\n",
    "weather icon does not give important information.\n",
    "and weather ID maps weather description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7f411c51-a843-47a8-83a2-a49543f92d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary and redundant columns\n",
    "columns_to_drop = ['weather_icon','weather_main', 'weather_description']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449824b-9c9b-4704-a59c-a0282a98ebae",
   "metadata": {},
   "source": [
    "##### Date and Time Feature Extraction:\n",
    "\n",
    "To capture the cyclical nature of weather patterns and ensure our model recognizes the seasonal, daily, and hourly variations in the data, we'll be extracting the following time-related features:\n",
    "\n",
    "- Month: This will help in recognizing monthly and seasonal trends. For instance, August might be generally warmer than January.\n",
    "- Day: Captures the day of the month.\n",
    "- Hour: Helps the model identify daily patterns. For example, midday might be warmer than early morning or late evening.\n",
    "- Day of the Week: Some patterns might be more prevalent on specific days, like weekends versus weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "83dd294d-54de-43a1-b46b-864cd5a4fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           dt   temp  visibility  dew_point  feels_like  temp_min  temp_max  \\\n",
      "0  1407628800  14.97     10000.0      13.00       14.82     14.95     14.99   \n",
      "1  1407632400  14.97     10000.0      13.00       14.82     14.95     14.99   \n",
      "2  1407636000  13.97     10000.0      13.02       13.88     13.95     14.39   \n",
      "3  1407639600  13.97     10000.0      13.02       13.88     13.95     14.39   \n",
      "4  1407643200  14.97     10000.0      14.01       14.98     14.95     15.51   \n",
      "\n",
      "   pressure  humidity  wind_speed  ...  scaled_temp  scaled_humidity  \\\n",
      "0      1016        88        0.51  ...     0.105661         0.832511   \n",
      "1      1015        88        0.51  ...     0.105661         0.832511   \n",
      "2      1015        94        1.03  ...     0.078008         1.161113   \n",
      "3      1015        94        1.03  ...     0.078008         1.161113   \n",
      "4      1015        94        1.54  ...     0.105661         1.161113   \n",
      "\n",
      "   rolling_avg_temp  rolling_avg_humidity  lag_temp  lag_humidity  month day  \\\n",
      "0         -0.000008             -0.000045 -0.000001     -0.000007      8  10   \n",
      "1         -0.000008             -0.000045  0.105661      0.832511      8  10   \n",
      "2         -0.000008             -0.000045  0.105661      0.832511      8  10   \n",
      "3         -0.000008             -0.000045  0.078008      1.161113      8  10   \n",
      "4         -0.000008             -0.000045  0.078008      1.161113      8  10   \n",
      "\n",
      "  day_of_week  hour  \n",
      "0           6     0  \n",
      "1           6     1  \n",
      "2           6     2  \n",
      "3           6     3  \n",
      "4           6     4  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'date' column to a datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract month, day, and day of the week\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['day_of_week'] = df['date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "\n",
    "# Extract hour from the 'time' column\n",
    "df['hour'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c0058-84dc-441c-86e1-aee159924e00",
   "metadata": {},
   "source": [
    "# 2. Create Yearly Samples\n",
    "We'll extract yearly samples from the dataset as you described, \n",
    "i.e., from 10th of August of one year to the 9th of August of the next year.\n",
    "\n",
    "## 2.1 Extract Yearly Data Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "74892e76-d87f-4006-a65d-ce6648d576bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store yearly samples\n",
    "yearly_samples = {}\n",
    "\n",
    "# Define the range of years we have in our dataset\n",
    "years = list(range(2014, 2023))\n",
    "\n",
    "# Extract samples for each year\n",
    "for year in years:\n",
    "    start_date = f\"{year}-08-10\"\n",
    "    end_date = f\"{year+1}-08-09\"\n",
    "    sample = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "    yearly_samples[year] = sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b076b-8903-44b5-a7e0-dce8e55b06d2",
   "metadata": {},
   "source": [
    "#### 2.2 Quick Inspection of the Yearly Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3e21ee96-304b-4dc1-850c-c10501ddcadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               dt   temp  visibility  dew_point  feels_like  temp_min  \\\n",
      "71842  1660089600  18.19         0.0      12.19       17.84     17.42   \n",
      "71843  1660093200  17.07         0.0      11.35       16.63     15.57   \n",
      "71844  1660096800  16.71         0.0      11.22       16.26     14.45   \n",
      "71845  1660100400  16.27         0.0      11.22       15.83     13.53   \n",
      "71846  1660104000  15.52         0.0      10.91       15.06     12.98   \n",
      "\n",
      "       temp_max  pressure  humidity  wind_speed  ...  scaled_temp  \\\n",
      "71842     18.95      1026        68        3.58  ...     0.194703   \n",
      "71843     18.39      1026        69        3.13  ...     0.163732   \n",
      "71844     18.91      1025        70        3.13  ...     0.153777   \n",
      "71845     18.35      1025        72        3.13  ...     0.141610   \n",
      "71846     17.24      1025        74        1.79  ...     0.120870   \n",
      "\n",
      "       scaled_humidity  rolling_avg_temp  rolling_avg_humidity  lag_temp  \\\n",
      "71842        -0.262829          0.287735             -1.045215  0.221526   \n",
      "71843        -0.208062          0.255856             -0.818323  0.194703   \n",
      "71844        -0.153295          0.227136             -0.614903  0.163732   \n",
      "71845        -0.043761          0.201498             -0.434954  0.153777   \n",
      "71846         0.065773          0.178348             -0.278477  0.141610   \n",
      "\n",
      "       lag_humidity  month day day_of_week  hour  \n",
      "71842     -0.536664      8  10           2     0  \n",
      "71843     -0.262829      8  10           2     1  \n",
      "71844     -0.208062      8  10           2     2  \n",
      "71845     -0.153295      8  10           2     3  \n",
      "71846     -0.043761      8  10           2     4  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "               dt   temp  visibility  dew_point  feels_like  temp_min  \\\n",
      "80597  1691607600  17.35         0.0      10.94       16.86     15.51   \n",
      "80598  1691611200  16.37         0.0      11.52       15.97     13.28   \n",
      "80599  1691614800  15.38         0.0      11.37       14.98     12.24   \n",
      "80600  1691618400  15.13         0.0      11.71       14.79     11.69   \n",
      "80601  1691622000  14.48         0.0      11.63       14.15     10.58   \n",
      "\n",
      "       temp_max  pressure  humidity  wind_speed  ...  scaled_temp  \\\n",
      "80597     18.32      1004        66        2.24  ...     0.171475   \n",
      "80598     17.77      1004        73        2.68  ...     0.144375   \n",
      "80599     16.66      1005        77        1.34  ...     0.116998   \n",
      "80600     16.66      1003        80        2.24  ...     0.110085   \n",
      "80601     16.10      1004        83        0.45  ...     0.092111   \n",
      "\n",
      "       scaled_humidity  rolling_avg_temp  rolling_avg_humidity  lag_temp  \\\n",
      "80597        -0.372363          0.211295             -0.677493  0.195256   \n",
      "80598         0.011006          0.195335             -0.536664  0.171475   \n",
      "80599         0.230074          0.179850             -0.395835  0.144375   \n",
      "80600         0.394375          0.164877             -0.231533  0.116998   \n",
      "80601         0.558676          0.146153             -0.028113  0.110085   \n",
      "\n",
      "       lag_humidity  month day day_of_week  hour  \n",
      "80597     -0.536664      8   9           2    19  \n",
      "80598     -0.372363      8   9           2    20  \n",
      "80599      0.011006      8   9           2    21  \n",
      "80600      0.230074      8   9           2    22  \n",
      "80601      0.394375      8   9           2    23  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the first few rows of the 2014 sample\n",
    "print(yearly_samples[2022].head())\n",
    "\n",
    "# Check the last few rows of the 2014 sample\n",
    "print(yearly_samples[2022].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ed68ad77-7a26-4b6c-b353-eb6c95f3808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_name4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548bb05-3419-4542-ae2b-e4d73ee429b6",
   "metadata": {},
   "source": [
    "# Model Selection & Training:\n",
    "## 1. Multi-Target Linear Regression\n",
    "\n",
    "In multi-target regression, we aim to predict multiple dependent variables using the same set of features. For our weather prediction task, this means predicting both temperature and humidity using our selected features.\n",
    "\n",
    "Using k-fold cross-validation, we will train our multi-target Linear Regression model on different yearly samples to ensure robustness and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e8982155-2bce-49ff-9e56-84b21da07262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Features and Targets\n",
    "features = [ 'rolling_avg_temp', 'rolling_avg_humidity', 'lag_temp', 'lag_humidity', 'month', 'day', 'day_of_week', 'hour']\n",
    "targets = ['temp','humidity','scaled_temp', 'scaled_humidity', 'weather_id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9b14b-bb32-43a0-9372-338fb7ca0e2c",
   "metadata": {},
   "source": [
    "##### Model Training with Cross-Validation:\n",
    "We'll train the model using 8 out of 9 samples and test on the remaining one, iterating through all possible combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "62fd93bb-5ff2-4be2-9acf-5dd9b9aa2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store evaluation metrics\n",
    "all_mae_temp, all_mse_temp, all_rmse_temp = [], [], []\n",
    "all_mae_humidity, all_mse_humidity, all_rmse_humidity = [], [], []\n",
    "all_mae_weather, all_mse_weather, all_rmse_weather = [], [], []\n",
    "all_mae_tempr, all_mse_tempr, all_rmse_tempr = [], [], []\n",
    "all_mae_humidityr, all_mse_humidityr, all_rmse_humidityr = [], [], []\n",
    "\n",
    "# Loop through each year for validation\n",
    "for year in yearly_samples.keys():\n",
    "    # Use all samples except the current year for training\n",
    "    train = pd.concat([yearly_samples[y] for y in yearly_samples.keys() if y != year])\n",
    "    test = yearly_samples[year]\n",
    "    \n",
    "    # Splitting data\n",
    "    X_train = train[features].dropna()\n",
    "    y_train = train.loc[X_train.index][targets]\n",
    "    X_test = test[features].dropna()\n",
    "    y_test = test.loc[X_test.index][targets]\n",
    "\n",
    "    # Model training\n",
    "    multi_target_model = LinearRegression()\n",
    "    multi_target_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting on test set\n",
    "    predictions = multi_target_model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    all_mae_temp.append(mean_absolute_error(y_test['scaled_temp'], predictions[:, 0]))\n",
    "    all_mse_temp.append(mean_squared_error(y_test['scaled_temp'], predictions[:, 0]))\n",
    "    all_rmse_temp.append(np.sqrt(all_mse_temp[-1]))\n",
    "    all_mae_humidity.append(mean_absolute_error(y_test['scaled_humidity'], predictions[:, 1]))\n",
    "    all_mse_humidity.append(mean_squared_error(y_test['scaled_humidity'], predictions[:, 1]))\n",
    "    all_rmse_humidity.append(np.sqrt(all_mse_humidity[-1]))\n",
    "    all_mae_weather.append(mean_absolute_error(y_test['weather_id'], predictions[:, 2]))\n",
    "    all_mse_weather.append(mean_squared_error(y_test['weather_id'], predictions[:, 2]))\n",
    "    all_rmse_weather.append(np.sqrt(all_mse_weather[-1]))\n",
    "    all_mae_tempr.append(mean_absolute_error(y_test['temp'], predictions[:, 2]))\n",
    "    all_mse_tempr.append(mean_squared_error(y_test['temp'], predictions[:, 2]))\n",
    "    all_rmse_tempr.append(np.sqrt(all_mse_tempr[-1]))\n",
    "    all_mae_humidityr.append(mean_absolute_error(y_test['humidity'], predictions[:, 2]))\n",
    "    all_mse_humidityr.append(mean_squared_error(y_test['humidity'], predictions[:, 2]))\n",
    "    all_rmse_humidityr.append(np.sqrt(all_mse_humidityr[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6a6ad-e115-41b8-9173-8b53fc7ed160",
   "metadata": {},
   "source": [
    "##### Results:\n",
    "After training and evaluating the model across all combinations, we can calculate the average performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c8740bfb-2a68-4b28-82cc-bd83b81d8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mae_temp = np.mean(all_mae_temp)\n",
    "avg_mse_temp = np.mean(all_mse_temp)\n",
    "avg_rmse_temp = np.mean(all_rmse_temp)\n",
    "avg_mae_humidity = np.mean(all_mae_humidity)\n",
    "avg_mse_humidity = np.mean(all_mse_humidity)\n",
    "avg_rmse_humidity = np.mean(all_rmse_humidity)\n",
    "avg_mae_weather = np.mean(all_mae_weather)\n",
    "avg_mse_weather = np.mean(all_mse_weather)\n",
    "avg_rmse_weather = np.mean(all_rmse_weather)\n",
    "avg_mae_humidityr = np.mean(all_mae_humidityr)\n",
    "avg_mse_humidityr = np.mean(all_mse_humidityr)\n",
    "avg_rmse_humidityr = np.mean(all_rmse_humidityr)\n",
    "avg_mae_tempr = np.mean(all_mae_tempr)\n",
    "avg_mse_tempr = np.mean(all_mse_tempr)\n",
    "avg_rmse_tempr = np.mean(all_rmse_tempr)\n",
    "\n",
    "#avg_mae_temp, avg_mse_temp, avg_rmse_temp, avg_mae_humidity, avg_mse_humidity, avg_rmse_humidity, avg_mae_weather, avg_mse_weather, avg_rmse_weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "35d6779a-c3b6-4642-b254-882e9b9f6b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Weather Condition</th>\n",
       "      <th>r_Temperature</th>\n",
       "      <th>r_Humidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error (MAE)</th>\n",
       "      <td>11.739861</td>\n",
       "      <td>73.235991</td>\n",
       "      <td>738.192366</td>\n",
       "      <td>11.669853</td>\n",
       "      <td>72.804660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error (MSE)</th>\n",
       "      <td>2236.129038</td>\n",
       "      <td>10126.306779</td>\n",
       "      <td>561098.269921</td>\n",
       "      <td>1461.275447</td>\n",
       "      <td>5639.450456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <td>27.288656</td>\n",
       "      <td>90.266453</td>\n",
       "      <td>749.034918</td>\n",
       "      <td>24.152677</td>\n",
       "      <td>75.079208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Temperature      Humidity  Weather Condition  \\\n",
       "Metric                                                                         \n",
       "Mean Absolute Error (MAE)         11.739861     73.235991         738.192366   \n",
       "Mean Squared Error (MSE)        2236.129038  10126.306779      561098.269921   \n",
       "Root Mean Squared Error (RMSE)    27.288656     90.266453         749.034918   \n",
       "\n",
       "                                r_Temperature   r_Humidity  \n",
       "Metric                                                      \n",
       "Mean Absolute Error (MAE)           11.669853    72.804660  \n",
       "Mean Squared Error (MSE)          1461.275447  5639.450456  \n",
       "Root Mean Squared Error (RMSE)      24.152677    75.079208  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame to display metrics\n",
    "metrics_data = {\n",
    "    'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)'],\n",
    "    'Temperature': [avg_mae_temp, avg_mse_temp, avg_rmse_temp],\n",
    "    'Humidity': [avg_mae_humidity, avg_mse_humidity, avg_rmse_humidity],\n",
    "    'Weather Condition': [avg_mae_weather, avg_mse_weather, avg_rmse_weather],\n",
    "    'r_Temperature': [avg_mae_tempr, avg_mse_tempr, avg_rmse_tempr],\n",
    "    'r_Humidity': [avg_mae_humidityr, avg_mse_humidityr, avg_rmse_humidityr]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_df.set_index('Metric', inplace=True)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e887703-8c71-46b8-996f-c533550d7913",
   "metadata": {},
   "source": [
    "#### Result analysis:\n",
    "from the table above we find that the model is okay for temperature but very bad for humidity in addition it is bad for weather id as it is a classification. which was expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165398c-de04-494f-8e09-24aaaab19c48",
   "metadata": {},
   "source": [
    "### Classification Model for Weather Condition (`weather_id`)\n",
    "\n",
    "To predict the specific weather condition represented by `weather_id`, we'll use a Random Forest classifier, a popular ensemble learning method known for its high accuracy, ability to handle large data sets with higher dimensionality, and its ability to handle missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "72b53ce2-6d1f-4310-9dd1-814ce68090d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         300       0.00      1.00      0.00         0\n",
      "         310       0.00      1.00      0.00         0\n",
      "         500       0.38      0.33      0.35      1464\n",
      "         501       0.17      0.03      0.05       163\n",
      "         502       0.00      0.00      1.00        17\n",
      "         520       0.00      1.00      0.00         0\n",
      "         600       0.29      0.03      0.06        62\n",
      "         601       1.00      0.00      0.00         3\n",
      "         701       0.00      1.00      0.00         0\n",
      "         741       0.00      1.00      0.00         0\n",
      "         800       0.18      0.84      0.30      1008\n",
      "         801       0.03      0.00      0.01       505\n",
      "         802       0.12      0.02      0.03       952\n",
      "         803       0.14      0.20      0.16      1347\n",
      "         804       0.56      0.08      0.14      3239\n",
      "\n",
      "    accuracy                           0.22      8760\n",
      "   macro avg       0.19      0.44      0.14      8760\n",
      "weighted avg       0.33      0.22      0.18      8760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# Data Preparation\n",
    "X_train = train[features].dropna()\n",
    "y_train_weather = train.loc[X_train.index]['weather_id']\n",
    "X_test = test[features].dropna()\n",
    "y_test_weather = test.loc[X_test.index]['weather_id']\n",
    "\n",
    "# Model Initialization and Training\n",
    "clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train_weather)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test_weather, y_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bf995-c68e-43c8-a27c-2f35b6a19a7b",
   "metadata": {},
   "source": [
    "## 2. Random Forest Regressor for Temperature and Humidity\n",
    "#### Introduction:\n",
    "\n",
    "Random forests are a powerful ensemble learning technique that can capture complex patterns in the data without needing explicit feature interaction terms.\n",
    "They are robust to outliers and can handle non-linear data.\n",
    "\n",
    "##### Random Forest Regression Model for Temperature and Humidity\n",
    "\n",
    "Now, we'll utilize the Random Forest Regression model to predict the temperature and humidity. Random forests are ensemble models that make predictions by combining the outputs of multiple decision trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0e65c398-33bf-49c7-9a5a-19627948a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model for temperature\n",
    "rf_model.fit(X_train, y_train['scaled_temp'])\n",
    "y_pred_temp = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model for temperature\n",
    "mae_temp = mean_absolute_error(y_test['scaled_temp'], y_pred_temp)\n",
    "mse_temp = mean_squared_error(y_test['scaled_temp'], y_pred_temp)\n",
    "rmse_temp = np.sqrt(mse_temp)\n",
    "\n",
    "# Train the model for humidity\n",
    "rf_model.fit(X_train, y_train['scaled_humidity'])\n",
    "y_pred_humidity = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model for humidity\n",
    "mae_humidity = mean_absolute_error(y_test['scaled_humidity'], y_pred_humidity)\n",
    "mse_humidity = mean_squared_error(y_test['scaled_humidity'], y_pred_humidity)\n",
    "rmse_humidity = np.sqrt(mse_humidity)\n",
    "\n",
    "#mae_temp, mse_temp, rmse_temp, mae_humidity, mse_humidity, rmse_humidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7c350e11-bb3a-46e7-9b0a-c135b9f03311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error (MAE)</th>\n",
       "      <td>0.043915</td>\n",
       "      <td>0.135819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error (MSE)</th>\n",
       "      <td>8.772526</td>\n",
       "      <td>0.040484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <td>2.961845</td>\n",
       "      <td>0.201207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Temperature  Humidity\n",
       "Metric                                               \n",
       "Mean Absolute Error (MAE)          0.043915  0.135819\n",
       "Mean Squared Error (MSE)           8.772526  0.040484\n",
       "Root Mean Squared Error (RMSE)     2.961845  0.201207"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame to display metrics\n",
    "metrics_data = {\n",
    "    'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)'],\n",
    "    'Temperature': [mae_temp, mse_temp, rmse_temp],\n",
    "    'Humidity': [mae_humidity, mse_humidity, rmse_humidity],\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_df.set_index('Metric', inplace=True)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a0079d-b186-4cf5-aa05-d79b7cf49eac",
   "metadata": {},
   "source": [
    "##### Random forest analysis\n",
    "from the result it seems that random forest has performed way better than linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b1b79-206d-45eb-9853-5edb380bcfd3",
   "metadata": {},
   "source": [
    "##### using K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8495653e-ac6f-46b6-a31f-308b1680f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Placeholder lists for metrics\n",
    "maes_temp = []\n",
    "mses_temp = []\n",
    "rmses_temp = []\n",
    "maes_humidity = []\n",
    "mses_humidity = []\n",
    "rmses_humidity = []\n",
    "\n",
    "# Features and targets\n",
    "#features = ['temp', 'visibility', 'dew_point', 'pressure', 'humidity', 'wind_speed', 'wind_deg', 'wind_gust', 'rain_1h', 'rain_3h', 'snow_1h', 'clouds_all', 'rolling_avg_temp', 'rolling_avg_humidity', 'lag_temp', 'lag_humidity', 'month', 'day', 'day_of_week', 'hour']\n",
    "targets = ['temp','humidity','scaled_temp', 'scaled_humidity']\n",
    "\n",
    "# Loop through each year for cross-validation\n",
    "for year, test_data in yearly_samples.items():\n",
    "    # Splitting the data\n",
    "    train_data = pd.concat([data for k, data in yearly_samples.items() if k != year])\n",
    "    \n",
    "    X_train = train_data[features]\n",
    "    y_train = train_data[targets]\n",
    "    X_test = test_data[features]\n",
    "    y_test = test_data[targets]\n",
    "    \n",
    "    # Training and predicting temperature\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train['scaled_temp'])\n",
    "    y_pred_temp = rf_model.predict(X_test)\n",
    "    \n",
    "    # Metrics for temperature\n",
    "    maes_temp.append(mean_absolute_error(y_test['scaled_temp'], y_pred_temp))\n",
    "    mses_temp.append(mean_squared_error(y_test['scaled_temp'], y_pred_temp))\n",
    "    rmses_temp.append(np.sqrt(mses_temp[-1]))\n",
    "    \n",
    "    # Training and predicting humidity\n",
    "    rf_model.fit(X_train, y_train['scaled_humidity'])\n",
    "    y_pred_humidity = rf_model.predict(X_test)\n",
    "    \n",
    "    # Metrics for humidity\n",
    "    maes_humidity.append(mean_absolute_error(y_test['scaled_humidity'], y_pred_humidity))\n",
    "    mses_humidity.append(mean_squared_error(y_test['scaled_humidity'], y_pred_humidity))\n",
    "    rmses_humidity.append(np.sqrt(mses_humidity[-1]))\n",
    "\n",
    "# Calculating average metrics\n",
    "avg_mae_temp = np.mean(maes_temp)\n",
    "avg_mse_temp = np.mean(mses_temp)\n",
    "avg_rmse_temp = np.mean(rmses_temp)\n",
    "avg_mae_humidity = np.mean(maes_humidity)\n",
    "avg_mse_humidity = np.mean(mses_humidity)\n",
    "avg_rmse_humidity = np.mean(rmses_humidity)\n",
    "\n",
    "#avg_mae_temp, avg_mse_temp, avg_rmse_temp, avg_mae_humidity, avg_mse_humidity, avg_rmse_humidity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "304c7aac-26e4-489b-b075-a1f8004b6baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error (MAE)</th>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.159993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error (MSE)</th>\n",
       "      <td>0.975006</td>\n",
       "      <td>0.052871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <td>0.344768</td>\n",
       "      <td>0.226619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Temperature  Humidity\n",
       "Metric                                               \n",
       "Mean Absolute Error (MAE)          0.015262  0.159993\n",
       "Mean Squared Error (MSE)           0.975006  0.052871\n",
       "Root Mean Squared Error (RMSE)     0.344768  0.226619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a DataFrame to display metrics\n",
    "metrics_data = {\n",
    "    'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)'],\n",
    "    'Temperature': [avg_mae_temp, avg_mse_temp, avg_rmse_temp],\n",
    "    'Humidity': [avg_mae_humidity, avg_mse_humidity, avg_rmse_humidity],\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_df.set_index('Metric', inplace=True)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ac4f8-fba3-400f-becd-bc4322b5d4ff",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regression Model with K-fold Cross-validation\n",
    "\n",
    "Gradient Boosting is a powerful ensemble technique that builds a model from the residuals of prior models, refining the predictions iteratively. Here, we implement it with k-fold cross-validation for a holistic evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f9b1d41c-4aa3-4c21-9919-036faa04669f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt',\n",
       " 'temp',\n",
       " 'visibility',\n",
       " 'dew_point',\n",
       " 'feels_like',\n",
       " 'temp_min',\n",
       " 'temp_max',\n",
       " 'pressure',\n",
       " 'humidity',\n",
       " 'wind_speed',\n",
       " 'wind_deg',\n",
       " 'wind_gust',\n",
       " 'rain_1h',\n",
       " 'rain_3h',\n",
       " 'snow_1h',\n",
       " 'clouds_all',\n",
       " 'weather_id',\n",
       " 'date',\n",
       " 'time',\n",
       " 'scaled_temp',\n",
       " 'scaled_humidity',\n",
       " 'rolling_avg_temp',\n",
       " 'rolling_avg_humidity',\n",
       " 'lag_temp',\n",
       " 'lag_humidity',\n",
       " 'month',\n",
       " 'day',\n",
       " 'day_of_week',\n",
       " 'hour']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86635f8d-60af-49ee-981f-37da82dae52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
